{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Deep Neural Network to predict housing prices\n",
    "\n",
    "We will assess what a price for a house will be based on historical data and 8 different parameters of information about each house, using a deep neural network.\n",
    "\n",
    "Credit to Khanrad on youtube: https://www.youtube.com/watch?v=zinEPDj7SD8&t="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Let's import the modules we will need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Import the data. \n",
    "\n",
    "Import the data and get a grip on how much data we are dealing with here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>854</td>\n",
       "      <td>1710</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2008</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1976</td>\n",
       "      <td>0</td>\n",
       "      <td>1262</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2007</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001</td>\n",
       "      <td>866</td>\n",
       "      <td>1786</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1915</td>\n",
       "      <td>756</td>\n",
       "      <td>1717</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>1053</td>\n",
       "      <td>2198</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YearBuilt  2ndFlrSF  GrLivArea  FullBath  HalfBath  BedroomAbvGr  \\\n",
       "0       2003       854       1710         2         1             3   \n",
       "1       1976         0       1262         2         0             3   \n",
       "2       2001       866       1786         2         1             3   \n",
       "3       1915       756       1717         1         0             3   \n",
       "4       2000      1053       2198         2         1             4   \n",
       "\n",
       "   TotRmsAbvGrd  YrSold  SalePrice  \n",
       "0             8    2008     208500  \n",
       "1             6    2007     181500  \n",
       "2             6    2008     223500  \n",
       "3             7    2006     140000  \n",
       "4             9    2008     250000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"housep.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1460"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To understand how large of a dataset we are dealing with here and the head function shows only the first 5, let's count the total # of rows in df. \n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next we set the x and y values. \n",
    "\n",
    "X = df.drop(columns=[\"SalePrice\"])\n",
    "Y = df[[\"SalePrice\"]]\n",
    "\n",
    "# See each one, remove the # to check.\n",
    "# x.head(3)\n",
    "# y.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential() #sequential because we don't need the complexity of a functional model here\n",
    "model.add(keras.layers.Dense(8, activation='relu', input_shape=(8,))) # 8 is describing the number of neurons, here we put 8 as there are 8 categories in the dataset. Doesnt mean this only the correct number of neurons,you will need to experiment with this. \n",
    "\n",
    "# Also, the more neurons above, the slower the network is gonna be to train. \n",
    "# Relu is basically telling the model that if a value is closer to 0, it will be zero, if it's closer to 1, it'll be one. \n",
    "\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1)) # for the salesprice\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we need to fit the model before we can start the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1460/1460 [==============================] - 1s 395us/step - loss: 38806091624.5041\n",
      "Epoch 2/30\n",
      "1460/1460 [==============================] - 0s 45us/step - loss: 38581351090.1479\n",
      "Epoch 3/30\n",
      "1460/1460 [==============================] - 0s 48us/step - loss: 38145149550.8164\n",
      "Epoch 4/30\n",
      "1024/1460 [====================>.........] - ETA: 0s - loss: 36586044928.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Olle/anaconda3/envs/envone/lib/python3.7/site-packages/keras/callbacks/callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460/1460 [==============================] - 0s 52us/step - loss: 37340966732.4493\n",
      "Epoch 5/30\n",
      "1460/1460 [==============================] - 0s 56us/step - loss: 36057890771.1123\n",
      "Epoch 6/30\n",
      "1460/1460 [==============================] - 0s 54us/step - loss: 34197037650.7616\n",
      "Epoch 7/30\n",
      "1460/1460 [==============================] - 0s 48us/step - loss: 31563401120.6137\n",
      "Epoch 8/30\n",
      "1460/1460 [==============================] - 0s 48us/step - loss: 28079612408.9863\n",
      "Epoch 9/30\n",
      "1460/1460 [==============================] - 0s 49us/step - loss: 24068963078.3123\n",
      "Epoch 10/30\n",
      "1460/1460 [==============================] - 0s 48us/step - loss: 19782769896.8548\n",
      "Epoch 11/30\n",
      "1460/1460 [==============================] - 0s 46us/step - loss: 15566021387.9233\n",
      "Epoch 12/30\n",
      "1460/1460 [==============================] - 0s 47us/step - loss: 11825925190.1370\n",
      "Epoch 13/30\n",
      "1460/1460 [==============================] - 0s 48us/step - loss: 8817415413.4795\n",
      "Epoch 14/30\n",
      "1460/1460 [==============================] - 0s 46us/step - loss: 6715166821.6986\n",
      "Epoch 15/30\n",
      "1460/1460 [==============================] - 0s 46us/step - loss: 5427560079.0795\n",
      "Epoch 16/30\n",
      "1460/1460 [==============================] - 0s 48us/step - loss: 4743531195.2658\n",
      "Epoch 17/30\n",
      "1460/1460 [==============================] - 0s 48us/step - loss: 4433808493.4137\n",
      "Epoch 18/30\n",
      "1460/1460 [==============================] - 0s 52us/step - loss: 4295254953.0301\n",
      "Epoch 19/30\n",
      "1460/1460 [==============================] - 0s 56us/step - loss: 4234031258.3014\n",
      "Epoch 20/30\n",
      "1460/1460 [==============================] - 0s 54us/step - loss: 4199644626.4110\n",
      "Epoch 21/30\n",
      "1460/1460 [==============================] - 0s 53us/step - loss: 4175814571.8356\n",
      "Epoch 22/30\n",
      "1460/1460 [==============================] - 0s 53us/step - loss: 4154171648.7014\n",
      "Epoch 23/30\n",
      "1460/1460 [==============================] - 0s 52us/step - loss: 4131615805.0192\n",
      "Epoch 24/30\n",
      "1460/1460 [==============================] - 0s 49us/step - loss: 4111109473.4904\n",
      "Epoch 25/30\n",
      "1460/1460 [==============================] - 0s 47us/step - loss: 4083417372.0548\n",
      "Epoch 26/30\n",
      "1460/1460 [==============================] - 0s 50us/step - loss: 4053857935.0795\n",
      "Epoch 27/30\n",
      "1460/1460 [==============================] - 0s 47us/step - loss: 4023512268.8000\n",
      "Epoch 28/30\n",
      "1460/1460 [==============================] - 0s 50us/step - loss: 3993847544.2849\n",
      "Epoch 29/30\n",
      "1460/1460 [==============================] - 0s 54us/step - loss: 3969813320.9425\n",
      "Epoch 30/30\n",
      "1460/1460 [==============================] - 0s 54us/step - loss: 3938658176.3507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x63ffeb690>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=30, callbacks=[keras.callbacks.EarlyStopping(patience=5)]) #epochs =30 means that we will go over the model 30 times.\n",
    "\n",
    "# callbacks helps us to not overfit the model. the # being 5 is something you can experiment with. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ok let's test the model\n",
    "\n",
    "For simplicities sake, we will take create an array which is identical to our first row of the dataset, to see if we get a similar salesprice that is in our dataset = 208 500.\n",
    "\n",
    "If you have new data to test on, that's gonna be than this solution. But once again, just to see that our model is giving us decently close result we will use the data we have. \n",
    "\n",
    "Let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[203431.38]]\n"
     ]
    }
   ],
   "source": [
    "test_data = np.array([2003, 854, 1710, 2, 1, 3, 8, 2008])\n",
    "\n",
    "print(model.predict(test_data.reshape(1,8), batch_size=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in this model we were roughly 4000 off, which is pretty damn close with how quick the training took. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What to do to improve this: \n",
    "\n",
    "1. Use a larger set of test data instead of one to make the assessment of: \"Is this a good or bad model\", which we've done here. \n",
    "\n",
    "2. Make it run more than 30 times. \n",
    "\n",
    "3. Play around with different number of neurons. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a great day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
